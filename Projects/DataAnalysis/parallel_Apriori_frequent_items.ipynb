{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84ae1011-0e84-44c6-90b9-18b6fd916e30",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db577dc-ea97-4790-997b-5718f559527b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain, combinations\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22aad0dc-3992-49c8-b986-bff63a049d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def itemsets_from_transactions(transactions, size):\n",
    "    return set(frozenset(itemset) for itemset in combinations(set(chain(*transactions)), size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c73633e-5667-4ab4-908a-5de6ce121d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_transaction(transaction, candidate_itemsets, next_freq_itemsets, min_support):\n",
    "    trans_set = frozenset(transaction)\n",
    "    for item in candidate_itemsets:\n",
    "        itemset = item\n",
    "        if isinstance(next(iter(itemset), None), frozenset):\n",
    "            itemset = frozenset([x for inner_set in item for x in inner_set])\n",
    "        if itemset.issubset(trans_set):\n",
    "            next_freq_itemsets[itemset] = next_freq_itemsets.get(itemset, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63d97805-6740-4908-b323-e50c468cb7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def frequent_itemsets(transactions, min_support):\n",
    "    #print(\"Start frequent mining process...\")\n",
    "    itemset_counts = defaultdict(int)\n",
    "    sorted_transactions = []\n",
    "    #print(\"Obtaining the 1-frequent items\")\n",
    "    for transaction in transactions:\n",
    "        sorted_t = sorted(transaction)\n",
    "        sorted_transactions.append(sorted_t)\n",
    "        for itemset in itemsets_from_transactions([sorted_t], 1):\n",
    "            itemset_counts[itemset] += 1\n",
    "\n",
    "    freq_itemsets = dict()\n",
    "    freq_itemsets[1] = {frozenset([item]): count for item, count in itemset_counts.items() if count >= min_support}\n",
    "\n",
    "    k = 1\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        while freq_itemsets[k]:\n",
    "            next_freq_itemsets = dict()\n",
    "            k += 1\n",
    "            #print(\"Obtaining the frequent items with size =\", k)\n",
    "            candidate_itemsets = itemsets_from_transactions(freq_itemsets[k - 1], k)\n",
    "\n",
    "            tasks = []\n",
    "            for transaction in sorted_transactions:\n",
    "                tasks.append(executor.submit(process_transaction, transaction, candidate_itemsets, next_freq_itemsets, min_support))\n",
    "\n",
    "            for task in concurrent.futures.as_completed(tasks):\n",
    "                pass\n",
    "\n",
    "            freq_itemsets[k] = {itemset: count for itemset, count in next_freq_itemsets.items() if count >= min_support}\n",
    "            #print(\"Done the frequent items with size =\", k)\n",
    "\n",
    "    #print(\"Done...\")\n",
    "    return freq_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74eef622-998a-4e53-a71e-30298397e3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(freq_itemsets):\n",
    "    result = {}\n",
    "    for k, v in freq_itemsets.items():\n",
    "        output_dict = {}\n",
    "        for key, value in v.items():\n",
    "            if value not in output_dict:\n",
    "                output_dict[value] = []\n",
    "            new_v = key\n",
    "            if isinstance(next(iter(new_v), None), frozenset): # verifying that the first element of new_v is a frozenset\n",
    "                new_v = [next(iter(inner)) for inner in new_v]\n",
    "            if len(new_v) == 1:\n",
    "                output_dict[value].append([x for x in new_v])\n",
    "            else:\n",
    "                output_dict[value].append(list(new_v))\n",
    "        if len(output_dict) > 0:\n",
    "            result[k] = output_dict\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21b77904-a416-4eb0-b1dc-14b7315f816b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.003220796585083008 seconds\n",
      "Result:\n",
      "1 {4: [[3], [2]], 3: [[1], [4]]}\n",
      "2 {2: [[1, 2], [1, 3], [3, 4], [2, 4], [1, 4]], 3: [[2, 3]]}\n",
      "3 {1: [[1, 2, 3], [2, 3, 4], [1, 2, 4], [1, 3, 4]]}\n"
     ]
    }
   ],
   "source": [
    "dataset = [[1, 2, 3], [2, 3, 4], [1, 2, 4], [1, 3, 4], [2, 3]]\n",
    "min_support = 1\n",
    "\n",
    "start_time = time.time()\n",
    "freq_itemsets = frequent_itemsets(dataset, min_support)\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(\"Execution time:\", execution_time, \"seconds\")\n",
    "\n",
    "print(\"Result:\")\n",
    "output = postprocess(freq_itemsets)\n",
    "for k, v in output.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa846750-9d14-41f0-b2f0-cd0050b8511a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
